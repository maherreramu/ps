{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install modin[ray]\n",
        "#!pip install -U ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GlGzG5dPbX4l"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from xml.etree import ElementTree as ET\n",
        "#import pandas as pd\n",
        "import modin.pandas as pd\n",
        "import os\n",
        "import concurrent.futures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.makedirs(\"raw_data\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v9HUNe8LfDNs"
      },
      "outputs": [],
      "source": [
        "endpoint = 'https://storage.googleapis.com/validaciones_tmsa/'\n",
        "def descargar_archivo(carpeta_destino, destino, url = endpoint):\n",
        "    file = os.path.join(carpeta_destino, destino.split('/')[-1])\n",
        "    print(f'Descargando {file}...')\n",
        "    response_headers = requests.head(url+destino)\n",
        "    print(f'Tamaño del archivo: {response_headers.headers[\"Content-Length\"]} bytes \\n estatus: {response_headers.status_code}')\n",
        "    response = requests.get(url+destino)\n",
        "    print(f'Estado de la descarga: {response.status_code}')\n",
        "    if response.status_code == 200:\n",
        "        with open(file, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        print(f'Archivo descargado a {file}.')\n",
        "    else:\n",
        "        print(f'Error al descargar el archivo: {response.status_code}')\n",
        "\n",
        "def descargar_archivos_paralelo(carpeta_destino, lista_destinos, url = endpoint):\n",
        "    print(f'Descargando {len(lista_destinos)} archivos en paralelo...')\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        print(f'Usando {executor._max_workers} hilos...')\n",
        "        executor.map(lambda x: descargar_archivo(carpeta_destino, x, url), lista_destinos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "4jeA1Clhsoy8"
      },
      "outputs": [],
      "source": [
        "def procesar_df(df):\n",
        "    columns = ['Fecha_Transaccion', 'Dispositivo', 'Estacion_Parada']\n",
        "    columns_upper = map(str.upper, columns)\n",
        "\n",
        "    df = df[columns]\n",
        "    df.columns = columns_upper\n",
        "\n",
        "    df = df[df['ESTACION_PARADA'].str.contains('U. NACIONAL', na=False)].drop('ESTACION_PARADA', axis=1).convert_dtypes()\n",
        "    df['DISPOSITIVO'] = df['DISPOSITIVO'].astype('int32')\n",
        "    df['FECHA_TRANSACCION'] = pd.to_datetime(df['FECHA_TRANSACCION'], format='%Y-%m-%d %H:%M:%S')\n",
        "    df['HORA'] = df['FECHA_TRANSACCION'].dt.time\n",
        "    df['FECHA_TRANSACCION'] = df['FECHA_TRANSACCION'].dt.date\n",
        "    df.sort_values(by=['FECHA_TRANSACCION', 'HORA'], ascending=[True, True], inplace=True)\n",
        "    df = df[df['HORA'].between(pd.to_datetime('16:00:00').time(), pd.to_datetime('18:30:00').time())]\n",
        "    df['HORA'] = pd.to_datetime(df['HORA'], format='%H:%M:%S')\n",
        "    df['DIFERENCIA'] = df.groupby(['FECHA_TRANSACCION', 'DISPOSITIVO'])['HORA'].diff().dt.total_seconds().fillna(0)\n",
        "    df.sort_values(by=['FECHA_TRANSACCION', 'DISPOSITIVO', 'HORA'], ascending=[True, True, True], inplace=True)\n",
        "    df['HORA'] = df['HORA'].dt.time\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "2EcqAe2nPxtU"
      },
      "outputs": [],
      "source": [
        "def procesar_df_lista(carpeta, file):\n",
        "    f_name = os.path.join(carpeta, file.split('/')[1])\n",
        "\n",
        "    try:\n",
        "        df_tmp = pd.read_csv(f_name)\n",
        "        df_tmp = procesar_df(df_tmp)\n",
        "        print(f'Data frame {f_name} procesado')\n",
        "        try:\n",
        "            os.remove(f_name)\n",
        "            print(f'Archivo {f_name} eliminado')\n",
        "        except Exception as e:\n",
        "            print(f'Error eliminando el archivo {f_name}: {e}')\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f'Error procesando el df {f_name}: {e}')\n",
        "        return None\n",
        "    return df_tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "NPuMiy7OYd75"
      },
      "outputs": [],
      "source": [
        "response = requests.get(endpoint)\n",
        "xml_data = response.text\n",
        "\n",
        "root = ET.fromstring(xml_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "H94J9z_xdgFa"
      },
      "outputs": [],
      "source": [
        "files = []\n",
        "\n",
        "namespace = {'ns': 'http://doc.s3.amazonaws.com/2006-03-01'}\n",
        "total_size = 0\n",
        "for element, size in zip(root.iterfind('.//ns:Key', namespace), root.iterfind('.//ns:Size', namespace)):\n",
        "    if 'validacionTroncal2024' in element.text:\n",
        "        files.append(element.text)\n",
        "        total_size += int(size.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamaño total: 44.95 GB\n"
          ]
        }
      ],
      "source": [
        "total_size_gb = total_size / (1024**3)\n",
        "print(f'Tamaño total: {total_size_gb:.2f} GB')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "86"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Espacio libre en el disco duro: 14.61 GB\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "total, used, free = shutil.disk_usage(\"/\")\n",
        "free_gb = free / (1024**3)\n",
        "\n",
        "print(f\"Espacio libre en el disco duro: {free_gb:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5i2BLBQ700W4",
        "outputId": "c6c9e642-f231-4c1a-be38-0a1e9f591b7f"
      },
      "outputs": [],
      "source": [
        "ingresos_ultimos_20d_2024= pd.DataFrame()\n",
        "\n",
        "files_to_download = files[:-20]\n",
        "length = len(files)\n",
        "batches = 6\n",
        "for i in range(batches):\n",
        "    print(f'Procesando batch {i+1}/{batches}...')\n",
        "    files_batch = files_to_download[i*length//batches:(i+1)*length//batches]\n",
        "    descargar_archivos_paralelo(\"raw_data\", files_batch)\n",
        "    dataframes = [procesar_df_lista(\"raw_data\", f) for f in files_batch]\n",
        "    ingresos_ultimos_20d_2024 = pd.concat([ingresos_ultimos_20d_2024] + dataframes, join='outer', ignore_index=True)\n",
        "\n",
        "print('**********TODOS LOS ARCHIVOS HAN SIDO PROCESADOS**********')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgnKriz2AYZI",
        "outputId": "74969c25-e992-4376-b924-dd6c42d45b08"
      },
      "outputs": [],
      "source": [
        "ingresos_ultimos_20d_2024.to_csv('ingresos_ultimos_20d_2024.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "ingresos_ultimos_20d_2024 = pd.read_csv('ingresos_ultimos_20d_2024.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
